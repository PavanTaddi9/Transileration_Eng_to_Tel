{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc94fe7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-11T05:52:46.156801Z",
     "iopub.status.busy": "2024-09-11T05:52:46.155835Z",
     "iopub.status.idle": "2024-09-11T05:52:46.979648Z",
     "shell.execute_reply": "2024-09-11T05:52:46.978216Z"
    },
    "papermill": {
     "duration": 0.832583,
     "end_time": "2024-09-11T05:52:46.982158",
     "exception": false,
     "start_time": "2024-09-11T05:52:46.149575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tttttt/train_folds.csv\n",
      "/kaggle/input/tttttt/train_dataset.csv\n",
      "/kaggle/input/tttttt/test_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818dd865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T05:52:46.992400Z",
     "iopub.status.busy": "2024-09-11T05:52:46.991409Z",
     "iopub.status.idle": "2024-09-11T05:53:03.353325Z",
     "shell.execute_reply": "2024-09-11T05:53:03.351670Z"
    },
    "papermill": {
     "duration": 16.369385,
     "end_time": "2024-09-11T05:53:03.355753",
     "exception": false,
     "start_time": "2024-09-11T05:52:46.986368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wtfml\r\n",
      "  Downloading wtfml-0.0.3-py3-none-any.whl.metadata (808 bytes)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/lib/python3.10/site-packages (from wtfml) (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->wtfml) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->wtfml) (1.14.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->wtfml) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->wtfml) (3.5.0)\r\n",
      "Downloading wtfml-0.0.3-py3-none-any.whl (10 kB)\r\n",
      "Installing collected packages: wtfml\r\n",
      "Successfully installed wtfml-0.0.3\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wtfml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a57e5921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T05:53:03.367403Z",
     "iopub.status.busy": "2024-09-11T05:53:03.366966Z",
     "iopub.status.idle": "2024-09-11T05:53:09.824489Z",
     "shell.execute_reply": "2024-09-11T05:53:09.823404Z"
    },
    "papermill": {
     "duration": 6.466547,
     "end_time": "2024-09-11T05:53:09.827144",
     "exception": false,
     "start_time": "2024-09-11T05:53:03.360597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import albumentations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from torch.nn import functional as F\n",
    "from wtfml.utils import EarlyStopping\n",
    "from wtfml.engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e5f282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T05:53:09.838616Z",
     "iopub.status.busy": "2024-09-11T05:53:09.838031Z",
     "iopub.status.idle": "2024-09-11T05:53:09.866394Z",
     "shell.execute_reply": "2024-09-11T05:53:09.865059Z"
    },
    "papermill": {
     "duration": 0.03761,
     "end_time": "2024-09-11T05:53:09.869473",
     "exception": false,
     "start_time": "2024-09-11T05:53:09.831863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, pixel_arrays, targets, resize=None, augmentations=None):\n",
    "        self.pixel_arrays = pixel_arrays\n",
    "        self.targets = targets\n",
    "        self.resize = resize\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pixel_arrays)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert the 1D array to a 2D grayscale image\n",
    "        image = np.array(self.pixel_arrays[idx], dtype=np.float32).reshape(48, 48)\n",
    "        \n",
    "        # Resize image if needed\n",
    "        if self.resize:\n",
    "            image = cv2.resize(image, self.resize)\n",
    "\n",
    "        # Expand dimensions to (48, 48, 1) and then convert to (new_size, new_size, 3) for RGB\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        image = np.repeat(image, 3, axis=-1)  # Convert to RGB\n",
    "\n",
    "        # Apply augmentations if specified\n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        # Convert image to PyTorch tensor and permute to (3, new_size, new_size) format\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)  # For RGB, shape becomes (3, new_size, new_size)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "\n",
    "        return image, target\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Engine:\n",
    "    @staticmethod\n",
    "    def train(data_loader, model, optimizer, device, scheduler=None, accumulation_steps=1, fp16=False):\n",
    "        model.train()\n",
    "        losses = AverageMeter()\n",
    "        scaler = torch.cuda.amp.GradScaler() if fp16 else None\n",
    "        \n",
    "        if accumulation_steps > 1:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for batch_idx, (images, targets) in enumerate(tk0):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                if fp16:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "                    scaler.scale(loss).backward()\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "                    loss.backward()\n",
    "\n",
    "                if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                    scaler.step(optimizer) if fp16 else optimizer.step()\n",
    "                    if scheduler:\n",
    "                        scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            losses.update(loss.item(), data_loader.batch_size)\n",
    "            tk0.set_postfix(loss=losses.avg)\n",
    "        \n",
    "        return losses.avg\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(data_loader, model, device, use_tpu=False):\n",
    "        losses = AverageMeter()\n",
    "        final_predictions = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                images, targets = data  # Adjust if your data format is different\n",
    "\n",
    "                # Move tensors to device\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                predictions, loss = model(images, targets)\n",
    "                predictions = predictions.cpu()\n",
    "                losses.update(loss.item(), images.size(0))\n",
    "                final_predictions.append(predictions)\n",
    "                tk0.set_postfix(loss=losses.avg)\n",
    "\n",
    "        # Concatenate all predictions and convert to NumPy array\n",
    "        final_predictions = torch.cat(final_predictions).numpy()\n",
    "        return final_predictions, losses.avg\n",
    "    def predict(data_loader, model, device, use_tpu=False):\n",
    "        model.eval()\n",
    "        final_predictions = []\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm(data_loader, total=len(data_loader), disable=use_tpu)\n",
    "            for b_idx, data in enumerate(tk0):\n",
    "                inputs, _ = data  # Unpack data\n",
    "                inputs = inputs.to(device)\n",
    "                predictions = model(inputs) \n",
    "                predictions = F.softmax(predictions,dim = 1)# Assume model returns only predictions\n",
    "                final_predictions.append(predictions.cpu())\n",
    "                tk0.set_postfix()\n",
    "        return torch.cat(final_predictions).numpy()\n",
    "        # Concatenate all predictions and convert to numpy array\n",
    "        return torch.cat(final_predictions).numpy()\n",
    "class AverageMeter():\n",
    "        def __init__(self):\n",
    "            self.reset()\n",
    "\n",
    "        def reset(self):\n",
    "            self.val = 0\n",
    "            self.avg = 0\n",
    "            self.sum = 0\n",
    "            self.count = 0\n",
    "\n",
    "        def update(self, val, n=1):\n",
    "            self.val = val\n",
    "            self.sum += val * n\n",
    "            self.count += n\n",
    "            self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ecefe5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T05:53:09.880745Z",
     "iopub.status.busy": "2024-09-11T05:53:09.880370Z",
     "iopub.status.idle": "2024-09-11T05:53:09.899434Z",
     "shell.execute_reply": "2024-09-11T05:53:09.898615Z"
    },
    "papermill": {
     "duration": 0.027238,
     "end_time": "2024-09-11T05:53:09.901587",
     "exception": false,
     "start_time": "2024-09-11T05:53:09.874349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from torch.utils.data import DataLoader\n",
    "def train(fold):\n",
    "    df = pd.read_csv(\"/kaggle/input/tttttt/train_folds.csv\")\n",
    "    device = \"cuda\"\n",
    "    epochs = 50\n",
    "    train_bs = 16\n",
    "    valid_bs = 16\n",
    "\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    train_pixels = df_train['pixels'].apply(lambda x: np.fromstring(x, sep=' ', dtype=np.float32))\n",
    "    train_targets = df_train['emotion'].values\n",
    "\n",
    "    valid_pixels = df_valid['pixels'].apply(lambda x: np.fromstring(x, sep=' ', dtype=np.float32))\n",
    "    valid_targets = df_valid['emotion'].values\n",
    "\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_aug = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=299, width=299),  # Resize images to 224x224\n",
    "        A.Normalize(mean=mean, std=std, max_pixel_value=255.0, always_apply=True),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n",
    "        A.HorizontalFlip(p=0.5)\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    valid_aug = A.Compose(\n",
    "        [\n",
    "        A.Resize(height=299, width=299),  # Resize images to 224x224\n",
    "        A.Normalize(mean=mean, std=std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "    train_dataset = CustomImageDataset(\n",
    "        pixel_arrays=train_pixels,\n",
    "        targets=train_targets,\n",
    "        resize=(299, 299),  # New size\n",
    "        augmentations=train_aug,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=16, shuffle=True, num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = CustomImageDataset(\n",
    "        pixel_arrays=valid_pixels,\n",
    "        targets=valid_targets,\n",
    "        resize=(299, 299),  # New size\n",
    "        augmentations=valid_aug,\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "    model = EF(num_classes= 7,pretrained='imagenet')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=3,\n",
    "        threshold=0.001,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(patience=5, mode=\"max\")\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = Engine.train(train_loader, model,optimizer,\n",
    "        device,\n",
    "        scheduler=None,\n",
    "        accumulation_steps=1,\n",
    "        fp16=False)\n",
    "        predictions, valid_loss = Engine.evaluate(\n",
    "            valid_loader, model, device=device\n",
    "        )\n",
    "        final_predictions = np.argmax(np.vstack(predictions), axis=1)\n",
    "        valid_targets = np.array(valid_targets)  # Ensure targets are in the right format\n",
    "    \n",
    "    # Calculate accuracy\n",
    "        accuracy = metrics.accuracy_score(valid_targets, final_predictions)\n",
    "        print(f\"Epoch = {epoch}, Accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "    # Update the learning rate scheduler\n",
    "        scheduler.step(accuracy)\n",
    "    \n",
    "    # Early Stopping\n",
    "        es(accuracy, model, model_path=f\"model_fold_EFAD512{fold}.bin\")\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    oof_data = {\n",
    "        'id': df_valid.index,  # Use the index to map back to the original data\n",
    "        'true_emotion': valid_targets,\n",
    "        'pred_emotion': final_predictions,\n",
    "        'fold': fold\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(oof_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac28ed11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T05:53:09.912704Z",
     "iopub.status.busy": "2024-09-11T05:53:09.911723Z",
     "iopub.status.idle": "2024-09-11T05:53:27.752232Z",
     "shell.execute_reply": "2024-09-11T05:53:27.750499Z"
    },
    "papermill": {
     "duration": 17.848245,
     "end_time": "2024-09-11T05:53:27.754660",
     "exception": false,
     "start_time": "2024-09-11T05:53:09.906415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\r\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet_pytorch) (2.4.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (2024.6.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\r\n",
      "Building wheels for collected packages: efficientnet_pytorch\r\n",
      "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=957252d960b347c1877941850cdc60c407dc66d5e70cb53e0b78d7319d9ff3fb\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\r\n",
      "Successfully built efficientnet_pytorch\r\n",
      "Installing collected packages: efficientnet_pytorch\r\n",
      "Successfully installed efficientnet_pytorch-0.7.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60756b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T05:53:27.768794Z",
     "iopub.status.busy": "2024-09-11T05:53:27.768394Z",
     "iopub.status.idle": "2024-09-11T05:53:27.785981Z",
     "shell.execute_reply": "2024-09-11T05:53:27.785017Z"
    },
    "papermill": {
     "duration": 0.027122,
     "end_time": "2024-09-11T05:53:27.788341",
     "exception": false,
     "start_time": "2024-09-11T05:53:27.761219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class EF(nn.Module):\n",
    "    def __init__(self, num_classes=7, model_name='efficientnet-b6', pretrained='imagenet'):\n",
    "        super(EF, self).__init__()\n",
    "        \n",
    "        # Load the pre-trained EfficientNet model\n",
    "        self.base_model = EfficientNet.from_pretrained(model_name) if pretrained == 'imagenet' else EfficientNet.from_name(model_name)\n",
    "        \n",
    "        # Replace the final fully connected layer with the new layer for multi-class classification\n",
    "        in_features = self.base_model._fc.in_features\n",
    "        self.base_model._fc = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    def forward(self, image, targets=None):\n",
    "        batch_size = image.size(0)\n",
    "        \n",
    "        # Forward pass through the base model\n",
    "        out = self.base_model(image)\n",
    "        \n",
    "        # If targets are provided, calculate the loss\n",
    "        if targets is not None:\n",
    "            loss = nn.CrossEntropyLoss()(out, targets)\n",
    "            return out, loss\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcbbd84e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T05:53:27.802030Z",
     "iopub.status.busy": "2024-09-11T05:53:27.801136Z",
     "iopub.status.idle": "2024-09-11T10:31:43.272419Z",
     "shell.execute_reply": "2024-09-11T10:31:43.270919Z"
    },
    "papermill": {
     "duration": 16695.480898,
     "end_time": "2024-09-11T10:31:43.275171",
     "exception": false,
     "start_time": "2024-09-11T05:53:27.794273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b6-c76e70fd.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b6-c76e70fd.pth\n",
      "100%|██████████| 165M/165M [00:01<00:00, 130MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:40<00:00,  1.13it/s, loss=1.6]\n",
      "100%|██████████| 63/63 [00:15<00:00,  3.98it/s, loss=1.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Accuracy = 0.4940\n",
      "Validation score improved (-inf --> 0.494). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:47<00:00,  1.10it/s, loss=1.17]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.92it/s, loss=1.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Accuracy = 0.5460\n",
      "Validation score improved (0.494 --> 0.546). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.881]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, Accuracy = 0.5770\n",
      "Validation score improved (0.546 --> 0.577). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.641]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, Accuracy = 0.5750\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.43]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.87it/s, loss=1.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, Accuracy = 0.5730\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.319]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, Accuracy = 0.5660\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.238]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, Accuracy = 0.5790\n",
      "Validation score improved (0.577 --> 0.579). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.173]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, Accuracy = 0.5740\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.161]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, Accuracy = 0.5890\n",
      "Validation score improved (0.579 --> 0.589). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.15]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, Accuracy = 0.5650\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.12]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, Accuracy = 0.5690\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.112]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, Accuracy = 0.5790\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0967]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, Accuracy = 0.5690\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0814]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, Accuracy = 0.5910\n",
      "Validation score improved (0.589 --> 0.591). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0623]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.92it/s, loss=1.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, Accuracy = 0.5960\n",
      "Validation score improved (0.591 --> 0.596). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0552]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.92it/s, loss=1.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, Accuracy = 0.5920\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0463]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, Accuracy = 0.5870\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0475]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 17, Accuracy = 0.5910\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0486]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 18, Accuracy = 0.5930\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0377]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 19, Accuracy = 0.5930\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=1.6]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Accuracy = 0.5210\n",
      "Validation score improved (-inf --> 0.521). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=1.19]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Accuracy = 0.5820\n",
      "Validation score improved (0.521 --> 0.582). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.908]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.87it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, Accuracy = 0.6000\n",
      "Validation score improved (0.582 --> 0.6). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.678]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, Accuracy = 0.6030\n",
      "Validation score improved (0.6 --> 0.603). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.455]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, Accuracy = 0.6090\n",
      "Validation score improved (0.603 --> 0.609). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.341]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, Accuracy = 0.6010\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.253]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, Accuracy = 0.6000\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.189]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, Accuracy = 0.6020\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.181]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, Accuracy = 0.6050\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.124]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, Accuracy = 0.6200\n",
      "Validation score improved (0.609 --> 0.62). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0952]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.92it/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, Accuracy = 0.6200\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0856]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, Accuracy = 0.6210\n",
      "Validation score improved (0.62 --> 0.621). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0799]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.92it/s, loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, Accuracy = 0.6290\n",
      "Validation score improved (0.621 --> 0.629). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0682]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, Accuracy = 0.6340\n",
      "Validation score improved (0.629 --> 0.634). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0623]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.89it/s, loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, Accuracy = 0.6250\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0559]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, Accuracy = 0.6310\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0558]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.92it/s, loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, Accuracy = 0.6310\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.06]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 17, Accuracy = 0.6280\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0477]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 18, Accuracy = 0.6290\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=1.6]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Accuracy = 0.4950\n",
      "Validation score improved (-inf --> 0.495). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=1.17]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Accuracy = 0.5510\n",
      "Validation score improved (0.495 --> 0.551). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.904]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, Accuracy = 0.5710\n",
      "Validation score improved (0.551 --> 0.571). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.666]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.92it/s, loss=1.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, Accuracy = 0.5830\n",
      "Validation score improved (0.571 --> 0.583). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.463]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, Accuracy = 0.5920\n",
      "Validation score improved (0.583 --> 0.592). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.318]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, Accuracy = 0.5750\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.238]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, Accuracy = 0.5640\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.196]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, Accuracy = 0.5810\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.149]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, Accuracy = 0.5760\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.134]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, Accuracy = 0.5920\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=1.59]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.88it/s, loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Accuracy = 0.4830\n",
      "Validation score improved (-inf --> 0.483). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=1.16]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Accuracy = 0.5580\n",
      "Validation score improved (0.483 --> 0.558). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.875]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, Accuracy = 0.5720\n",
      "Validation score improved (0.558 --> 0.572). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.655]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, Accuracy = 0.5550\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.471]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.88it/s, loss=1.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, Accuracy = 0.5400\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.314]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, Accuracy = 0.5660\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.262]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, Accuracy = 0.5780\n",
      "Validation score improved (0.572 --> 0.578). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.178]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.92it/s, loss=1.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, Accuracy = 0.5760\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.165]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.89it/s, loss=1.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, Accuracy = 0.5770\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.137]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, Accuracy = 0.5750\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.129]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=1.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, Accuracy = 0.5840\n",
      "Validation score improved (0.578 --> 0.584). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.124]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.89it/s, loss=1.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, Accuracy = 0.5630\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.101]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=1.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, Accuracy = 0.5820\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0961]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, Accuracy = 0.5890\n",
      "Validation score improved (0.584 --> 0.589). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0899]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=2.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, Accuracy = 0.5630\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.0854]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.87it/s, loss=2.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, Accuracy = 0.5530\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0709]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.90it/s, loss=2.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, Accuracy = 0.5790\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0619]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=2.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 17, Accuracy = 0.5630\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:48<00:00,  1.09it/s, loss=0.0588]\n",
      "100%|██████████| 63/63 [00:16<00:00,  3.91it/s, loss=2.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 18, Accuracy = 0.5630\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "dffold2 = train(1)\n",
    "dffold3 = train(2)\n",
    "dffold4 = train(3)\n",
    "dffold5 = train(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351b2398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T10:31:50.969330Z",
     "iopub.status.busy": "2024-09-11T10:31:50.968429Z",
     "iopub.status.idle": "2024-09-11T10:31:50.979436Z",
     "shell.execute_reply": "2024-09-11T10:31:50.978312Z"
    },
    "papermill": {
     "duration": 3.897543,
     "end_time": "2024-09-11T10:31:50.981646",
     "exception": false,
     "start_time": "2024-09-11T10:31:47.084103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(fold):\n",
    "    df = pd.read_csv(\"/kaggle/input/emo-map-challenge/test_dataset.csv\")\n",
    "    device = \"cuda\"\n",
    "    model_path=f\"model_fold_EF(384){fold}.bin\"\n",
    "    test_pixels = df['pixels'].apply(lambda x: np.fromstring(x, sep=' ', dtype=np.float32))                 \n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(height=384, width=384),\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "                                      \n",
    "    targets = np.zeros(len(df))\n",
    "    test_dataset = CustomImageDataset(\n",
    "        pixel_arrays=test_pixels,\n",
    "        targets=targets,\n",
    "        resize=None,\n",
    "        augmentations=aug,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    model = model = EfficientNetForMultiClass(pretrained='imagenet')\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "\n",
    "    predictions = Engine.predict(test_loader, model, device=device)\n",
    "    predictions = np.vstack((predictions))\n",
    "    return predictions\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5675669,
     "sourceId": 9360861,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16754.795115,
   "end_time": "2024-09-11T10:31:57.880532",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-11T05:52:43.085417",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
